{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOKEN-BASED SIMILARITY\n",
    "\n",
    "Token-based similarity measures compare two strings by first dividing them into a set of tokens\n",
    "using a tokenization function, which we denote as tokenize(Â·). Intuitively, tokens correspond to\n",
    "substrings of the original string. As a simple example, assume the tokenization function splits a\n",
    "string into tokens based on whitespace characters.Then, the string Sean Connery results in the set\n",
    "of tokens *{Sean,Connery}*. As we will show throughout our discussion, the main advantage of\n",
    "token-based similarity measures is that the similarity is less sensitive to word swaps compared to\n",
    "similarity measures that consider a string as a whole (notably edit-based measures). That is, the\n",
    "comparison of *Sean Connery* and *Connery Sean* will yield a maximum similarity score because both\n",
    "strings contain the exact same tokens. On the other hand, typographical errors within tokens are\n",
    "penalized, for instance, the similarity of *Sean Connery* and *Shawn Conery* will be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JACCARD COEFFICIENT\n",
    "\n",
    "The Jaccard coefficient is a similarity measure that, in its most general form, compares two sets P\n",
    "and Q with the following formula:\n",
    "$$Jaccard(P,Q) = \\frac{|P \\cap Q|}{|P \\cup Q|}$$\n",
    "Essentially,the Jaccard coefficient measures the fraction of the data that is shared between P\n",
    "and Q, compared to all data available in the union of these two sets.\n",
    "\n",
    "An advantage of the Jaccard coefficient is that it is not sensitive to word swaps. Indeed, the\n",
    "score of two names *John Smith* and *Smith John* would correspond to the score of exactly equal strings because the Jaccard coefficient considers only whether a token exists in a string, not at which position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18181818181818182 Jaccard Distance between sent1 and sent2\n",
      "0.36 Jaccard Distance between sent1 and sent3\n",
      "0.0 Jaccard Distance between sent1 and sent4\n",
      "0.22727272727272727 Jaccard Distance between sent1 and sent5\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "sent1 = set(\"It might help to re-install Python if possible.\")\n",
    "sent2 = set(\"It can help to install Python again if possible.\")\n",
    "sent3 = set(\"It can be so helpful to reinstall C++ if possible.\")\n",
    "sent4 = set(\"help It possible Python to re-install if might.\") # This has the same words as sent1 with a different order.\n",
    "sent5 = set(\"I love Python programming.\")\n",
    " \n",
    "jd_sent_1_2 = nltk.jaccard_distance(sent1, sent2)\n",
    "jd_sent_1_3 = nltk.jaccard_distance(sent1, sent3)\n",
    "jd_sent_1_4 = nltk.jaccard_distance(sent1, sent4)\n",
    "jd_sent_1_5 = nltk.jaccard_distance(sent1, sent5)\n",
    " \n",
    " \n",
    "print(jd_sent_1_2, 'Jaccard Distance between sent1 and sent2')\n",
    "print(jd_sent_1_3, 'Jaccard Distance between sent1 and sent3')\n",
    "print(jd_sent_1_4, 'Jaccard Distance between sent1 and sent4')\n",
    "print(jd_sent_1_5, 'Jaccard Distance between sent1 and sent5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COSINE SIMILARITY USINGTOKEN FREQUENCY AND INVERSE DOCUMENT FREQUENCY\n",
    "\n",
    "The cosine similarity is a similarity measure often used in information retrieval. In general,given two n-dimensional vectors V and W, the cosine similarity computes the cosine of the angle $\\alpha$ between\n",
    "these two vectors as\n",
    "$$CosineSimilarity(V,W) = cos(\\alpha) = \\frac{V \\cdot W}{||V|| \\cdot ||W||}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat and dog like food',\n",
       " 'cat like cat food',\n",
       " 'dog like dog food',\n",
       " 'horse like dog']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem = PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "texts = ['cats and dogs like food',\n",
    "          'cats like cat food',\n",
    "          'dogs like dog food',\n",
    "          'horses like dogs']\n",
    "i=0\n",
    "for text in texts:\n",
    "    lem_words = []\n",
    "    tokenized_word=word_tokenize(text)\n",
    "    for word in tokenized_word:\n",
    "        lem_words.append(lem.lemmatize(word,\"v\"))\n",
    "        #print(\"Stemmed Word:\",stem.stem(word))   \n",
    "        #print(lem.lemmatize(words))\n",
    "    texts[i] = \" \".join(lem_words)\n",
    "    i=i+1\n",
    "texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>food</th>\n",
       "      <th>horse</th>\n",
       "      <th>like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  cat  dog  food  horse  like\n",
       "0    1    1    1     1      0     1\n",
       "1    0    2    0     1      0     1\n",
       "2    0    0    2     1      0     1\n",
       "3    0    0    1     0      1     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvec = CountVectorizer()\n",
    "smat = cvec.fit_transform(texts)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# make the DTM\n",
    "dtm = pd.DataFrame(smat.toarray(), columns=cvec.get_feature_names())\n",
    "\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.73029674, 0.73029674, 0.51639778],\n",
       "       [0.73029674, 1.        , 0.33333333, 0.23570226],\n",
       "       [0.73029674, 0.33333333, 1.        , 0.70710678],\n",
       "       [0.51639778, 0.23570226, 0.70710678, 1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "sklearn.metrics.pairwise.cosine_similarity(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn.metrics.pairwise.cosine_similarity(dtm, np.array([0,0,0,0,1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDIT-BASED SIMILARITY\n",
    "\n",
    "We now focus on a second family of similarity measures,so called edit-based similarity measures.\n",
    "In contrast to token-based measures, strings are considered as a whole and are not divided into sets\n",
    "of tokens. However, to account for errors, such as typographical errors, word swaps and so on, edit-\n",
    "based similarities allow different edit operations to transform one string into the other,e.g.,*insertion* of characters, character *swaps*, *deletion* of characters, or *replacement* of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple 7\n",
      "bag 6\n",
      "drawing 4\n",
      "listing 1\n",
      "linking 2\n",
      "living 2\n",
      "lighting 1\n",
      "orange 6\n",
      "walking 4\n",
      "zoo 7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    " \n",
    "mistake = \"ligting\"\n",
    " \n",
    "words = ['apple', 'bag', 'drawing', 'listing', 'linking', 'living', 'lighting', 'orange', 'walking', 'zoo']\n",
    " \n",
    "for word in words:\n",
    "    ed = nltk.edit_distance(mistake, word)\n",
    "    print(word, ed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correction('korrectud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval('banana', 'bahama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import stringdist\n",
    "stringdist.levenshtein('test', 'testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your own Spelling Corrector\n",
    "\n",
    "Here are the four pillars of our spelling checker:\n",
    "\n",
    "1. **Selection Mechanism**: argmax\n",
    "    We choose the candidate with the highest combined probability.\n",
    "\n",
    "2. **Candidate Model**: c â candidates\n",
    "    This tells us which candidate corrections, c, to consider.\n",
    "\n",
    "3. **Language Model**: P(c)\n",
    "    The probability that c appears as a word of English text. For example, occurrences of \"the\" make up about 7% of English text, so we should have P(the) = 0.07.\n",
    "\n",
    "4. **Error Model**: P(w|c)\n",
    "    The probability that w would be typed in a text when the author meant c. For example, P(teh|the) is relatively high, but P(theeexyz|the) would be very low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidates: \n",
    "\n",
    "We entertain all words within a constant stringdistance as candidates for the correctly spelled word.\n",
    "\n",
    "First a new concept: a simple edit to a word is a deletion (remove one letter), a transposition (swap two adjacent letters), a replacement (change one letter to another) or an insertion (add a letter). The function **edits1** returns a set of all the edited strings (whether words or not) that can be made with one simple edit: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a big set. For a word of length n, there will be $n$ deletions, $n-1$ transpositions, $26n$ alterations, and $26(n+1)$ insertions, for a total of $54n+25$ (of which a few are typically duplicates). For example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edits1('somthing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we restrict ourselves to words that are knownâthat is, in the dictionaryâ then the set is much smaller.\n",
    "Why not read in all Harry Potter novels and define them as our dictionary.\n",
    "\n",
    "The function *words* breaks text into words, then the variable WORDS holds a Counter of how often each word appears, and *P* estimates the probability of each word, based on this Counter: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system(\"cat data/HP/*.txt > big.txt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(words(open('data/HP/big.txt', encoding='latin-1').read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'something', 'soothing'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def known(words): return set(w for w in words if w in WORDS)\n",
    "\n",
    "known(edits1('somthing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also consider corrections that require two simple edits. This generates a much bigger set of possibilities, but usually only a few of them are known words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edits2(word): return ____\n",
    "\n",
    "len(set(edits2('something'))\n",
    "\n",
    "known(edits2('something'))\n",
    "\n",
    "known(edits2('somthing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Language Model: P(c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P(word, N=sum(WORDS.values())): return WORDS[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015779535814197303"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WORDS.most_common(100)\n",
    "P('looking')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection Mechanism: \n",
    "\n",
    "In Python, max with a key argument does 'argmax'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(WORDS,key=P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplified Error model\n",
    "\n",
    "Write a function *candidates(word)* that produces the first non-empty list of candidates in order of priority:\n",
    "\n",
    "1. The original word, if it is known; otherwise\n",
    "2. The list of known words at edit distance one away, if there are any; otherwise\n",
    "3. The list of known words at edit distance two away, if there are any; otherwise\n",
    "4. The original word, even though it is not known. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(word): return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " correction('speling')              # insert\n",
    " correction('korrectud')            # replace 2\n",
    " correction('bycycle')                # replace\n",
    " correction('inconvient')       # insert 2\n",
    " correction('arrainged')            # delete\n",
    " correction('peotry')                  # transpose\n",
    " correction('peotryy')                # transpose + delete\n",
    " correction('word')                      # known"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "### Bayes Theorem\n",
    "\n",
    "So far, the error model P(w|c) has been trivial: the smaller the edit distance, the smaller the error. \n",
    "\n",
    "A good spelling corrector would be much more sophisticated by relying on Bayes theorem.\n",
    "\n",
    "We are trying to find the correction c, out of all possible candidate corrections, that maximizes the probability that c is the intended correction, given the original word w: \n",
    "\n",
    "$$\n",
    "P(c | w) = \\frac{P(c) P(w|c) }{P(w)} \\sim P(c) P(w|c)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we could use a better model of the cost of edits. We could use our intuition to assign lower costs for doubling letters and changing a vowel to another vowel (as compared to an arbitrary letter change), but it seems better to gather data: to get a corpus of spelling errors, and count how likely it is to make each insertion, deletion, or alteration, given the surrounding characters. We need a lot of data to do this well. If we want to look at the change of one character for another, given a window of two characters on each side, that's 266, which is over 300 million characters. You'd want several examples of each, on average, so we need at least a billion characters of correction data; probably safer with at least 10 billion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
